# enhanced_setup_chromadb.py
import json
import chromadb
from sentence_transformers import SentenceTransformer
import numpy as np
from typing import List, Dict

# --- Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø­Ø³Ù†Ø© ---
MODEL_NAME = 'intfloat/multilingual-e5-large'
JSON_FILE_PATH = 'data.json'
PERSIST_DIRECTORY = "my_chroma_db"  
COLLECTION_NAME = "recruitment_qa" 

def load_knowledge_base(file_path):
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        print(f"ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(data)} Ø³Ø¤Ø§Ù„ ÙˆØ¬ÙˆØ§Ø¨ Ù…Ù† '{file_path}'.")
        return data
    except FileNotFoundError:
        print(f"Ø®Ø·Ø£: Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ù Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© '{file_path}'.")
        return []

def preprocess_text(text: str) -> str:
    """ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù†ØµÙˆØµ Ù‚Ø¨Ù„ Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ embeddings"""
    import re
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…ØªØªØ§Ù„ÙŠØ© ÙˆØ§Ù„Ø±Ù…ÙˆØ² Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©
    text = re.sub(r'\d+', ' Ø±Ù‚Ù… ', text)
    # ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª
    text = re.sub(r'\s+', ' ', text)
    # Ø¥Ø²Ø§Ù„Ø© Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ±Ù‚ÙŠÙ… Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©
    text = re.sub(r'[^\w\s\u0600-\u06FF]', ' ', text)
    return text.strip()

def create_enhanced_embeddings(questions: List[str], answers: List[str], model) -> tuple:
    """Ø¥Ù†Ø´Ø§Ø¡ embeddings Ù…Ø­Ø³Ù†Ø© Ù„Ù„Ø£Ø³Ø¦Ù„Ø© ÙˆØ§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª Ù…Ø¹Ø§Ù‹"""
    enhanced_texts = []
    
    for q, a in zip(questions, answers):
        # ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù†ØµÙˆØµ
        clean_q = preprocess_text(q)
        clean_a = preprocess_text(a)
        
        # Ø¯Ù…Ø¬ Ø§Ù„Ø³Ø¤Ø§Ù„ ÙˆØ§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ù„ÙÙ‡Ù… Ø£ÙØ¶Ù„ Ù„Ù„Ø³ÙŠØ§Ù‚
        combined_text = f"Ø³Ø¤Ø§Ù„: {clean_q} Ø¥Ø¬Ø§Ø¨Ø©: {clean_a}"
        enhanced_texts.append(f"query: {combined_text}")
    
    print("Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ embeddings Ù…Ø­Ø³Ù†Ø©...")
    embeddings = model.encode(
        enhanced_texts, 
        normalize_embeddings=True, 
        show_progress_bar=True,
        batch_size=32  # ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡
    )
    
    return embeddings, enhanced_texts

# --- ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ---
print(f"Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­Ø³Ù†: {MODEL_NAME}...")
model = SentenceTransformer(MODEL_NAME)
print("ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­.")

# --- Ø¥Ø¹Ø¯Ø§Ø¯ ChromaDB ---
client = chromadb.PersistentClient(path=PERSIST_DIRECTORY)

print(f"Ø¬Ø§Ø±ÙŠ Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ù…Ø­Ø³Ù†Ø© '{COLLECTION_NAME}' ÙÙŠ ChromaDB...")
try:
    client.delete_collection(name=COLLECTION_NAME)
    print("ØªÙ… Ø­Ø°Ù Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© Ø¨Ù†Ø¬Ø§Ø­.")
except Exception as e:
    print(f"Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ù‚Ø¯ÙŠÙ…Ø©: {e}")

# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨Ù…Ø¹Ø§ÙŠÙŠØ± ØªØ´Ø§Ø¨Ù‡ Ù…Ø­Ø³Ù†Ø©
collection = client.create_collection(
    name=COLLECTION_NAME,
    metadata={"hnsw:space": "cosine"}  # Ø§Ø³ØªØ®Ø¯Ø§Ù… cosine similarity Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
)
print("ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ù…Ø­Ø³Ù†Ø© Ø¨Ù†Ø¬Ø§Ø­.")

# --- Ù‚Ø±Ø§Ø¡Ø© ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ---
knowledge_base = load_knowledge_base(JSON_FILE_PATH)
if not knowledge_base:
    print("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©. ØªÙ… Ø¥Ù†Ù‡Ø§Ø¡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©.")
else:
    questions = [item['question'] for item in knowledge_base]
    answers = [item['answer'] for item in knowledge_base]
    ids = [str(i) for i in range(len(questions))]

    # Ø¥Ù†Ø´Ø§Ø¡ embeddings Ù…Ø­Ø³Ù†Ø©
    embeddings, enhanced_texts = create_enhanced_embeddings(questions, answers, model)
    
    print(f"ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {len(embeddings)} Ù…ØªØ¬Ù‡ Ù…Ø­Ø³Ù†. Ø¬Ø§Ø±ÙŠ Ø¥Ø¶Ø§ÙØªÙ‡Ø§ Ø¥Ù„Ù‰ ChromaDB...")
    
    # Ø¥Ø¶Ø§ÙØ© metadata Ù…Ø­Ø³Ù†Ø©
    metadatas = []
    for i, (q, a) in enumerate(zip(questions, answers)):
        metadata = {
            "question": q,
            "answer": a,
            "question_clean": preprocess_text(q),
            "answer_clean": preprocess_text(a),
            "combined_text": enhanced_texts[i],
            "id": str(i)
        }
        metadatas.append(metadata)
    
    collection.add(
        embeddings=embeddings.tolist(),
        metadatas=metadatas,
        ids=ids
    )

    print("=" * 60)
    print(f"âœ… Ù†Ø¬Ø§Ø­! ØªÙ… ØªØ®Ø²ÙŠÙ† {collection.count()} Ù…Ø³ØªÙ†Ø¯ Ù…Ø­Ø³Ù† ÙÙŠ ChromaDB")
    print(f"ğŸ“ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø­ÙÙˆØ¸Ø© ÙÙŠ: '{PERSIST_DIRECTORY}'")
    print("ğŸ” Ø§Ù„Ù†Ø¸Ø§Ù… Ø¬Ø§Ù‡Ø² Ù„Ù„Ø¨Ø­Ø« Ø§Ù„Ø°ÙƒÙŠ ÙˆØ§Ù„Ø¯Ù‚ÙŠÙ‚")
    print("=" * 60)